{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Reproducible Environments\n",
    "(Continued from `README.md`)\n",
    "\n",
    "## Overview\n",
    "\n",
    "* Requirements: The Bare Minimum \n",
    "\n",
    "* Using a Data Science Template: `cookiecutter`\n",
    "\n",
    "* Virtual Environments: `conda` and environment files\n",
    "* Revision Control: git and a git workflow\n",
    "   * Installing, Enabling, and using nbdime\n",
    "* The Data Science DAG\n",
    "   * make, Makefiles and data flow\n",
    "* Python Modules\n",
    "   * Creating an editable module\n",
    "* Testing: doctest, pytest, hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start out by checking that all the requirements are met from the previous exercises (started in `README.md`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Install the requirements\n",
    "\n",
    "* Anaconda\n",
    "* Cookiecutter\n",
    "* make\n",
    "* git\n",
    "\n",
    "***Note***: You don't need cookiecutter in your `bus_number_tutorial` environment (the one you should be using to run this notebook). We already used it to **build** the `bus_number_tutorial` current environment in the `TUTORIAL.md` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda --version   # or `$CONDA_EXE --version` in some environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Start your cookiecutter-based project\n",
    "\n",
    "Create a project called `Bus Number Tutorial`:\n",
    "\n",
    "    Use conda as your virtualenv manager\n",
    "    Use python 3.6 or greater\n",
    "\n",
    "When complete, you should have a fully populated project directory, complete with customized README.md.\n",
    "\n",
    "We will be working in this project from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "\n",
    "<pre>\n",
    " $ <b>cookiecutter https://github.com/hackalog/cookiecutter-easydata.git --checkout bus_number</b>\n",
    "\n",
    "project_name [project_name]: <b>Bus Number Tutorial</b>\n",
    "repo_name [bus_number_tutorial]: <b>↵</b>\n",
    "module_name [src]: <b>↵</b>\n",
    "author_name [Your name (or your organization/company/team)]: <b>hackalog</b>\n",
    "description [A short description of this project.]: <b>Reproducible Data Science</b>\n",
    "Select open_source_license:\n",
    "1 - MIT\n",
    "2 - BSD-2-Clause\n",
    "3 - Proprietary\n",
    "Choose from 1, 2, 3 [1]: <b>↵</b>\n",
    "s3_bucket [[OPTIONAL] your-bucket-for-syncing-data (do not include 's3://')]: <b>↵</b>\n",
    "aws_profile [default]: <b>↵</b>\n",
    "Select virtualenv:\n",
    "1 - conda\n",
    "2 - virtualenv\n",
    "Choose from 1, 2 [1]: <b>↵</b>\n",
    "Select python_interpreter:\n",
    "1 - python3\n",
    "2 - python\n",
    "Choose from 1, 2 [1]: <b>↵</b>\n",
    "\n",
    "\n",
    " $ <b>cd bus_number_tutorial</b>\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "\n",
    "Explore the `README.md` from your new `bus_number_tutorial` repo\n",
    "\n",
    "(Hint: You can use the `%load` magic, or `!cat` to look at it in your notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bus Number Tutorial\n",
    "==============================\n",
    "\n",
    "Reproducible data science tutorial\n",
    "\n",
    "GETTING STARTED\n",
    "---------------\n",
    "\n",
    "For complete instructions, visit: https://github.com/hackalog/bus_number/wiki/Getting-Started\n",
    "\n",
    "* Create and switch to the  virtual environment:\n",
    "```\n",
    "cd bus_number_tutorial\n",
    "make create_environment\n",
    "conda activate bus_number_tutorial\n",
    "make requirements\n",
    "```\n",
    "* Explore the notebooks in the `notebooks` directory\n",
    "\n",
    "Project Organization\n",
    "------------\n",
    "* `LICENSE`\n",
    "* `Makefile`\n",
    "    * top-level makefile. Type `make` for a list of valid commands\n",
    "* `README.md`\n",
    "    * this file\n",
    "* `data`\n",
    "    * Data directory. often symlinked to a filesystem with lots of space\n",
    "    * `data/raw`\n",
    "        * Raw (immutable) hash-verified downloads\n",
    "    * `data/interim`\n",
    "        * Extracted and interim data representations\n",
    "    * `data/processed`\n",
    "        * The final, canonical data sets for modeling.\n",
    "* `docs`\n",
    "    * A default Sphinx project; see sphinx-doc.org for details\n",
    "* `models`\n",
    "    * Trained and serialized models, model predictions, or model summaries\n",
    "    * `models/trained`\n",
    "        * Trained models\n",
    "    * `models/output`\n",
    "        * predictions and transformations from the trained models\n",
    "* `notebooks`\n",
    "    *  Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "    the creator's initials, and a short `-` delimited description,\n",
    "    e.g. `1.0-jqp-initial-data-exploration`.\n",
    "* `references`\n",
    "    * Data dictionaries, manuals, and all other explanatory materials.\n",
    "* `reports`\n",
    "    * Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "    * `reports/figures`\n",
    "        * Generated graphics and figures to be used in reporting\n",
    "    * `reports/tables`\n",
    "        * Generated data tables to be used in reporting\n",
    "    * `reports/summary`\n",
    "        * Generated summary information to be used in reporting\n",
    "* `requirements.txt`\n",
    "    * (if using pip+virtualenv) The requirements file for reproducing the\n",
    "    analysis environment, e.g. generated with `pip freeze > requirements.txt`\n",
    "* `environment.yml`\n",
    "    * (if using conda) The YAML file for reproducing the analysis environment\n",
    "* `setup.py`\n",
    "    * Turns contents of `src` into a\n",
    "    pip-installable python module  (`pip install -e .`) so it can be\n",
    "    imported in python code\n",
    "* `src`\n",
    "    * Source code for use in this project.\n",
    "    * `src/__init__.py`\n",
    "        * Makes src a Python module\n",
    "    * `src/data`\n",
    "        * Scripts to fetch or generate data. In particular:\n",
    "        * `src/data/make_dataset.py`\n",
    "            * Run with `python -m src.data.make_dataset fetch`\n",
    "            or  `python -m src.data.make_dataset process`\n",
    "    * `src/analysis`\n",
    "        * Scripts to turn datasets into output products\n",
    "    * `src/models`\n",
    "        * Scripts to train models and then use trained models to make predictions.\n",
    "        e.g. `predict_model.py`, `train_model.py`\n",
    "* `tox.ini`\n",
    "    * tox file with settings for running tox; see tox.testrun.org\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "<p><small>This project was built using <a target=\"_blank\" href=\"https://github.com/hackalog/cookiecutter-easydata\">cookiecutter-easydata</a>, an experimental fork of [cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science) aimed at making your data science workflow reproducible.</small></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Set up your virtual environment and install all dependencies\n",
    "\n",
    "Create and activate your `bus_number_tutorial` conda environment using the above make commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `active environment` should be `bus_number_tutorial`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you are using **JupyterHub**, the bash magics `!` and `%%bash` will not work as expected, that is, they will drop you into your root JupyterHub environment, as opposed to the conda kernel that you a running this notebook in, and you will not see `bus_number_tutorial`. To get around this, you will need to run the bash commands in this notebook from a terminal instance with your `bus_number_tutorial` conda environment activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, you should also be able to import from `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if importing src doesn't work, try `make requirements`\n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Pick up this tutorial in your new repo\n",
    "\n",
    "* Run jupyter notebook and open `notebooks/10-reproducible-environment.ipynb`\n",
    "\n",
    "If you're currently running this notebook and the checks from the previous exercises worked, then you're in business!\n",
    "\n",
    "Keep going from here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Control: `git`\n",
    "\n",
    "How do we keep track of our changes? We use **git**.\n",
    "\n",
    "Before we do anything interesting, let's initialize a git repository (repo) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Initialize a git repo for `bus_number_tutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial Import\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see: \n",
    "    \n",
    "    # On branch master\n",
    "    nothing to commit, working directory clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get back to using git again soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Add a dependency\n",
    "Modify the environment file so that `make requirements` installs some additional packages\n",
    "* install `joblib` using conda\n",
    "* install `nbdime` using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be able to see the difference via git\n",
    "!git diff ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6\n",
    "Your `environment.yml` should look like this now:\n",
    "<pre>\n",
    "name: bus_number_tutorial\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - pip\n",
    "  - pip:\n",
    "    - -e .\n",
    "    - python-dotenv>=0.5.1\n",
    "    <b>- nbdime</b>\n",
    "  - setuptools\n",
    "  - wheel\n",
    "  - sphinx\n",
    "  - click\n",
    "  - coverage\n",
    "  - pytest-cov\n",
    "  - jupyter\n",
    "  <b>- joblib</b>\n",
    "  - nb_conda\n",
    "  - nbval\n",
    "  - pandas\n",
    "  - requests\n",
    "  - python>=3.6\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you now have joblib  and nbdime installed\n",
    "# Don't forget that you need to run `make requirements` once you've change the `environment.yml` file\n",
    "import joblib\n",
    "import nbdime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be able to see the difference via git\n",
    "!git diff ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Basic git interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what has changed with git:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git diff -u ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add or reject the changes incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git add -p\n",
    "#!git reset -p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git commit -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should have no differences in your branch now\n",
    "# Except for those that you've made by running notebooks\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science DAG\n",
    "DAG = Directed Acyclic Graph. \n",
    "\n",
    "That means the process eventually stops. (This is a good thing!) \n",
    "\n",
    "It also means we can use a super old, but incredibly handy tool to implement this workflow: `make`.\n",
    "\n",
    "### Make, Makefiles, and the Data Flow\n",
    "\n",
    "\n",
    "We use a `Makefile` to organize and invoke the various steps in our Data Science pipeline.\n",
    "You have already used this file when you created your virtual environment in the first place:\n",
    "```\n",
    "make create_environment\n",
    "```\n",
    "Here are the steps we will be working through in this tutorial:\n",
    "<img src=\"references/cheat_sheet.png\" alt=\"Reproducible Data Science Workflow\" width=\"400\"/>\n",
    "\n",
    "A [PDF version of the cheat sheet](references/cheat_sheet.pdf) is also available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What's my make target doing?\n",
    "If you are ever curious what commands a `make` command will invoke (including any invoked dependencies), use `make -n`, which lists the commands without executing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd .. && make -n requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a cute **self-documenting makefiles trick** (borrowed from `cookiecutter-datascience`) to make it easy to document the various targets that you add. This documentation is produced when you type a plain `make`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd .. && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the Hood: The Format of a Makefile\n",
    "\n",
    "```\n",
    "## Comment to appear in the auto-generated documentation\n",
    "thing_to_build: space separated list of dependencies\n",
    "\tcommand_to_run            # there is a tab before this command.\n",
    "\tanother_command_to_run    # every line gets run in a *new shell*\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "data: raw\n",
    "\t@echo \"Build Datasets\"\n",
    "train_test_split:\n",
    "\t@echo \"do train/test split\"\n",
    "train: data transform_data train_test_split\n",
    "\t@echo \"Train Models\"\n",
    "transform_data:\n",
    "\t@echo \"do a data transformation\"\n",
    "raw:\n",
    "\t@echo \"Fetch raw data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you can run a specific Makefile with with -f option\n",
    "!make -f Makefile.test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you see: ```*** missing separator.  Stop.``` it's because you have used spaces instead of **tabs** before your commands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: What does this makefile print when you run `make train`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "make -f Makefile.test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: What happens when you add a cycle to a Makefile\n",
    "Set up a makefile with a cyclic dependency and run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "cycle: cycle_b\n",
    "\t@echo \"in a Makefile\"\n",
    "cycle_b: cycle_c\n",
    "\t@echo \"have a cycle\"\n",
    "cycle_c: cycle\n",
    "\t@echo \"You can't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "make -f Makefile.test cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Makefile like this is an easy way to set up a process flow expressed as a Directed Acyclic Graph (DAG).\n",
    "\n",
    "**Note**: We have only scratched the surface here. The are lots of interesting tricks you can do with make.\n",
    "* http://zmjones.com/make/\n",
    "* http://blog.byronjsmith.com/makefile-shortcuts.html\n",
    "* https://www.gnu.org/software/make/manual/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Revision Control: git workflows\n",
    "\n",
    "Git isn't really a collaboration tool. It's more a tool for implementing collaboration workflows.\n",
    "\n",
    "What do we mean by workflow? A process built on top of git that incorporates **pull requests** and **branches**. Typically, this is provided by sites like: GitHub, GitLab, BitBucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: \n",
    "\n",
    "Create a GitHub/GitLab/BitBucket repo and sync your repo to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "See https://help.github.com/articles/create-a-repo/ to start a GitHub repo.\n",
    "\n",
    "**Note** Since you already have a repo with readme and license, you do **not** want to choose the option to initialize the repo with those. \n",
    "\n",
    "Once you have a github repo called `bus_number_tutorial`:\n",
    "\n",
    "**Using http**\n",
    "\n",
    "    git remote add origin <your new repo URL eg. https://github.com/${GITHUB_USERNAME}/bus_number_tutorial.git>\n",
    "    git push -u origin master\n",
    "\n",
    "**Using SSL**\n",
    "\n",
    "    git remote add origin <your new repo: git@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git>\n",
    "    git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your remote repo should now show up\n",
    "!git remote -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example (using SSL):\n",
    "\n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (fetch)\n",
    "   \n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (push)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub workflow cheatsheet\n",
    "See https://github.com/hackalog/bus_number/wiki/Github-Workflow-Cheat-Sheet\n",
    "\n",
    "## Life Rules for using `git`\n",
    "\n",
    "* Always work on a branch: `git checkout -b my_branch_name`. Delete branches once they are merged.\n",
    "* **Never** push to master. Always **work on a branch** and do a pull request.\n",
    "* Seriously, don't do work on master if you are collaborating with **anyone**.\n",
    "* If you pushed it anywhere, or shared it with anyone, don't `git rebase`. In fact, if you're reading this, don't `git rebase`. Save that for when you are comfortable solving git merge nightmares on your own.\n",
    "\n",
    "Here are some common tasks in git/github\n",
    "\n",
    "### Starting the day. Where was I? What was I doing?\n",
    "```\n",
    "git branch         # What branch am I currently on? e.g. {my_branch}\n",
    "git status         # anything I forgot to commit? If so...\n",
    "git commit ...     # Commit work in progress\n",
    "```\n",
    "\n",
    "### Didn't I do some work at home last night?\n",
    "```\n",
    "git checkout master       # leave whatever branch I was on\n",
    "git fetch origin --prune  # Check for something new\n",
    "git merge origin/master   # If updates available, update!\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "### Anything fun happening upstream?\n",
    "\n",
    "```\n",
    "git checkout master\n",
    "git fetch upstream --prune  # grab latest changes from upstream repo\n",
    "git merge upstream/master   # merge them into local copy of my form\n",
    "git push origin master      # push latest upstream changes to my forked repo\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "Now that `master` is up to date, you should merge whatever happened in `master` into your development branch:\n",
    "```\n",
    "git checkout {my_branch}\n",
    "git merge master               # merges master->{my_branch}\n",
    "git push origin {my_branch}    # Let Github know about the merge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful references if `gitflow` isn't second nature to you yet\n",
    "* Introduction to GitHub tutorial: https://lab.github.com/githubtraining/introduction-to-github\n",
    "* Git Handbook: https://guides.github.com/introduction/git-handbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11:\n",
    "* Create a branch called `add_sklearn`\n",
    "* Add a scikit-learn dependency\n",
    "* Check in these changes using git to your local repo\n",
    "* Push the new branch to GitHub\n",
    "* Create a pull request to merge this branch into master\n",
    "* Merge your PR (delete the branch afterwards)\n",
    "* Sync your local repo with GitHub, including deleting the merged branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "\n",
    "* Create a branch called `add_sklearn`\n",
    "    \n",
    "    `git checkout -b add_sklearn`\n",
    "    \n",
    "* Add a scikit-learn dependency\n",
    "    * Add `scikit-learn` to the `environment.yml` file\n",
    "    * `make requirements`\n",
    "* Check in these changes using git to your local repo\n",
    "    * `git add -p`\n",
    "    * `git commit -m \"add scikit-learn dependency\"`\n",
    "* Push the new branch to GitHub\n",
    "    * `git push origin add_sklearn`\n",
    "* Create a pull request to merge this branch into master\n",
    "    * Go to the URL that gets generated from the previous step and create a PR\n",
    "* Merge your PR (delete the branch afterwards)\n",
    "    * Follow GitHub/BitBucket instructions for merging your PR and then deleting the `add_sklearn` branch\n",
    "* Sync your local repo with GitHub, including deleting the merged branches\n",
    "    * `git checkout master`\n",
    "    * `git fetch origin --prune`\n",
    "    * `git merge origin/master`\n",
    "    * `git branch --merged master` should now display `add_sklearn` indicating that that branch has been merged into `master`\n",
    "    * `git branch -d add_sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should now only have a branch called master\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Modules\n",
    "By default, we keep our source code in a module called `src`. (this can be overridden in the cookieccutter)\n",
    "\n",
    "This is enabled via one line in `environment.yml`:\n",
    "```\n",
    "- pip:\n",
    "  - -e .\n",
    "```\n",
    "\n",
    "This creates an **editable module**, and looks in the current directory for a file called `setup.py` to indicate the module name and location"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load ../setup.py\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='src',\n",
    "    packages=find_packages(),\n",
    "    version='0.0.1',\n",
    "    description='Up Your Bus Number: A Primer for Reproducible Data Science',\n",
    "    author='Tutte Institute for Mathematics and Computing',\n",
    "    license='MIT',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets you easily use your code in notebooks and other scripts, and avoids any `sys.path.append` silliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Semantic Versioning\n",
    "\n",
    "Semantic versioning (or *semver*), refers to the convention of versioning with a triple:\n",
    "\n",
    "    MAJOR.MINOR.PATCH\n",
    "\n",
    "With the following convention: when releasing new versions, increment the:\n",
    "\n",
    "*    MAJOR version when you make **incompatible API changes**,\n",
    "*    MINOR version when you **add functionality** in a backwards-compatible manner, and\n",
    "*    PATCH version when you make backwards-compatible **bug fixes**.\n",
    "\n",
    "If you have no other plan, this is a great convention to follow.\n",
    "\n",
    "For an obscene amount of detail on this concept, see https://semver.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12:\n",
    "* add your favorite utility function to `src/utils`\n",
    "* increment the version number of the editable package\n",
    "* run `make requirements` (required if you added dependencies for your utility function)\n",
    "* import your utility function and run it from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add our utility function (note the `-a` flag with the `%%file` magic that allows us to append instead of overwrite the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file -a ../src/utils.py\n",
    "def read_space_delimited(filename, skiprows=None, class_labels=True, metadata=None):\n",
    "    \"\"\"Read an space-delimited file\n",
    "    \n",
    "    Data is space-delimited. Last column is the (string) label for the data\n",
    "\n",
    "    Note: we can't use automatic comment detection, as `#` characters are also\n",
    "    used as data labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    skiprows: list-like, int or callable, optional\n",
    "        list of rows to skip when reading the file. See `pandas.read_csv`\n",
    "        entry on `skiprows` for more\n",
    "    class_labels: boolean\n",
    "        if true, the last column is treated as the class (target) label\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as fd:\n",
    "        df = pd.read_csv(fd, skiprows=skiprows, skip_blank_lines=True,\n",
    "                           comment=None, header=None, sep=' ', dtype=str)\n",
    "        # targets are last column. Data is everything else\n",
    "        if class_labels is True:\n",
    "            target = df.loc[:, df.columns[-1]].values\n",
    "            data = df.loc[:, df.columns[:-1]].values\n",
    "        else:\n",
    "            data = df.values\n",
    "            target = np.zeros(data.shape[0])\n",
    "        return data, target, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increment the version number to `0.0.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../setup.py\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='src',\n",
    "    packages=find_packages(),\n",
    "    version='0.0.2',\n",
    "    description='A short description of this project.',\n",
    "    author='Your name (or your organization/company/team)',\n",
    "    license='MIT',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A handy magic that allows us to edit modules and have them stay up to date in the notebook. In this case, src.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import read_space_delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_space_delimited?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: doctest, pytest, coverage\n",
    "\n",
    "\n",
    "Python has built in testing frameworks via:\n",
    "* doctests:https://docs.python.org/3/library/doctest.html#module-doctest\n",
    "* unittest: https://docs.python.org/3/library/unittest.html\n",
    "\n",
    "Additionally, you'll want to make regular use of:\n",
    "* pytest: https://docs.pytest.org/en/latest/\n",
    "* pytest-cov: https://pypi.org/project/pytest-cov/\n",
    "* hypothesis: https://hypothesis.readthedocs.io/en/latest\n",
    "\n",
    "Cookiecutter (vanilla flavoured) comes witha setup for the `tox` testing framework built in.\n",
    "* https://tox.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12:\n",
    "\n",
    "Add a `make test` target to your makefile that:\n",
    "* runs doctests\n",
    "* runs pytest unit tests\n",
    "* (extra credit) Displays test coverage results\n",
    "    \n",
    "When you run `make test`, you will find tests that will fail in `src/test_example.py`. Fix them in the next exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 12:\n",
    "\n",
    "    test:\n",
    "        cd src && pytest --doctest-modules --verbose --cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && make -n test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cd src && pytest --doctest-modules --verbose --cov\n",
    "    ============================= test session starts ==============================\n",
    "    platform linux -- Python 3.6.7, pytest-4.2.1, py-1.7.0, pluggy-0.8.1 -- /opt/software/anaconda3/envs/bus_number_tutorial/bin/python\n",
    "    cachedir: .pytest_cache\n",
    "    rootdir: ~/src/devel/bus_number_tutorial, inifile:\n",
    "    plugins: cov-2.6.1, nbval-0.9.1\n",
    "    collected 7 items                                                              \n",
    "\n",
    "    test_example.py::src.test_example.addition FAILED                        [ 14%]\n",
    "    test_example.py::TestExercises::test_addition FAILED                     [ 28%]\n",
    "    data/fetch.py::src.data.fetch.available_hashes PASSED                    [ 42%]\n",
    "    data/fetch.py::src.data.fetch.fetch_file PASSED                          [ 57%]\n",
    "    data/fetch.py::src.data.fetch.fetch_files PASSED                         [ 71%]\n",
    "    data/fetch.py::src.data.fetch.get_dataset_filename PASSED                [ 85%]\n",
    "    data/utils.py::src.data.utils.normalize_labels PASSED                    [100%]\n",
    "\n",
    "    =================================== FAILURES ===================================\n",
    "    _____________________ [doctest] src.test_example.addition ______________________\n",
    "    004 \n",
    "    005     I'm a failing doctest. Please fix me.\n",
    "    006     >>> addition(10, 12)\n",
    "    Expected:\n",
    "        20\n",
    "    Got:\n",
    "        -2\n",
    "\n",
    "    ~/src/devel/bus_number_tutorial/src/test_example.py:6: DocTestFailure\n",
    "    _________________________ TestExercises.test_addition __________________________\n",
    "\n",
    "    self = <src.test_example.TestExercises testMethod=test_addition>\n",
    "\n",
    "        def test_addition(self):\n",
    "            \"\"\"\n",
    "            I'm a failing unittest. Fix me.\n",
    "            \"\"\"\n",
    "    >       assert subtraction(5, 5) == 0\n",
    "    E       AssertionError: assert 10 == 0\n",
    "    E         -10\n",
    "    E         +0\n",
    "\n",
    "    test_example.py:22: AssertionError\n",
    "\n",
    "    ----------- coverage: platform linux, python 3.6.7-final-0 -----------\n",
    "    Name                         Stmts   Miss  Cover\n",
    "    ------------------------------------------------\n",
    "    __init__.py                      0      0   100%\n",
    "    analysis/__init__.py             0      0   100%\n",
    "    analysis/analysis.py           105     86    18%\n",
    "    analysis/run_analysis.py        23      9    61%\n",
    "    data/__init__.py                 4      0   100%\n",
    "    data/apply_transforms.py        27     12    56%\n",
    "    data/datasets.py               311    262    16%\n",
    "    data/fetch.py                  143    109    24%\n",
    "    data/localdata.py                1      0   100%\n",
    "    data/make_dataset.py            15      4    73%\n",
    "    data/transform_data.py          88     72    18%\n",
    "    data/transformers.py            42     29    31%\n",
    "    data/utils.py                   85     61    28%\n",
    "    features/__init__.py             0      0   100%\n",
    "    features/build_features.py       0      0   100%\n",
    "    logging.py                       7      0   100%\n",
    "    models/__init__.py               3      0   100%\n",
    "    models/algorithms.py             5      4    20%\n",
    "    models/model_list.py            74     60    19%\n",
    "    models/predict.py              100     80    20%\n",
    "    models/predict_model.py         22      9    59%\n",
    "    models/train.py                 54     39    28%\n",
    "    models/train_models.py          25     11    56%\n",
    "    paths.py                        17      0   100%\n",
    "    test_example.py                  8      0   100%\n",
    "    utils.py                        58     45    22%\n",
    "    visualization/__init__.py        0      0   100%\n",
    "    visualization/visualize.py       0      0   100%\n",
    "    workflow.py                      8      0   100%\n",
    "    ------------------------------------------------\n",
    "    TOTAL                         1225    892    27%\n",
    "\n",
    "    ====================== 2 failed, 5 passed in 1.69 seconds ======================\n",
    "    make: *** [test] Error 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** `make test` is normally functionality built into `cookiecutter-easydata`. We're building it from scratch here for the sake of practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13:\n",
    "Fix the failing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../src/test_example.py\n",
    "import unittest\n",
    "\n",
    "def addition(n1, n2):\n",
    "    \"\"\"\n",
    "    I'm addition\n",
    "    >>> addition(10, 10)\n",
    "    20\n",
    "    \"\"\"\n",
    "    return n1 + n2\n",
    "\n",
    "def subtraction(n1, n2):\n",
    "    \"\"\"\n",
    "    I'm subtraction.\n",
    "    \"\"\"\n",
    "    return n1 - n2\n",
    "\n",
    "class TestExercises(unittest.TestCase):\n",
    "    def test_subtraction(self):\n",
    "        \"\"\"\n",
    "        I'm a failing unittest. Fix me.\n",
    "        \"\"\"\n",
    "        assert subtraction(5, 5) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should pass all tests now!\n",
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14:\n",
    "* Check in all your changes to git\n",
    "* Merge them into your master branch via a PR in GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
